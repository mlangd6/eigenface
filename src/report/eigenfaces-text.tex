\documentclass[12pt,french]{article}

\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}

% quelques définitions
\theoremstyle{plain}
\newtheorem{thm}{Théorème}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{dem}{Démonstration}

\theoremstyle{definition}
\newtheorem{defi}{Définition}
\newtheorem{rmq}{Remarque}
\newtheorem{ex}{Exemple}
\newtheorem{exo}{exercice}

% opérateurs pour les probabilités
\DeclareMathOperator\Var{Var}
\DeclareMathOperator\Cov{Cov}
\DeclareMathOperator\esp{E}


\title{Eigenfaces}
\author{
  Bouarah Romain \and
  Langdorph Matthieu \and
  Ketels Lucas \and
  Souffan Nathan
}


\begin{document}
\maketitle
\newpage

\section*{Introduction}
L’omniprésence de l’informatique, la puissance des ordinateurs, l’efficacité des algorithmes, ainsi que la facilité d’acquérir des images, par l’intermédiaire de caméras et d’appareils photo, nous permet d’automatiser le processus de reconnaissance d’images, et plus particulièrement de reconnaissance de visages.
Le recours aux technologies de reconnaissance faciale est, de fait, de plus en plus important dans de nombreux secteurs d’activité, et commence à modifier l’usage que nous faisons de différents appareils, outils et applications.
Par ailleurs, la reconnaissance faciale est l’objet de nombreuses recherches, à la fois mathématiques et informatiques, ce qui donne lieu à une certaine diversité de techniques et technologies pour aboutir à la reconnaissance effective de visages.
Nous soulignerons que l’usage de technologies de reconnaissance faciale soulève des enjeux moraux, politiques et économiques, ainsi que des risques et questions quant à nos libertés fondamentales.
Aussi préciserons-nous qu’une mauvaise connaissance du terme “reconnaissance faciale” et de ce à quoi il fait référence peut conduire à une évaluation erronée des risques et enjeux liés cette technologie, ainsi qu’à une confusion quant aux technologies proches, voisines de la reconnaissance faciale.
Il est notamment important de faire la distinction entre détection de visages et reconnaissance faciale: cette dernière est une techniques biométrique, c’est-à-dire un ensemble de procédés automatisés permettant de reconnaître un individu à partir de la quantification de ses caractéristiques physiques, physiologiques ou comportementales.
Nous nous demanderons comment les différentes technologies de reconnaissance faciale ont émergées, et nous nous interrogerons sur les risques et enjeux que soulèvent ces dernières au sein de notre société.
Pour ce faire, nous étudierons dans un premier temps le développement mathématiques et informatique de la reconnaissance faciale, nous nous pencherons dans un second temps sur les différentes utilisations de cette technologie, pour enfin nous intéresser aux risques et enjeux qu’elle soulève.

\part{Le développement des différentes technologies de reconnaissance faciale}

\section{Introduction à la méthode EigenFace}
La recherche et les premières méthodes significatives de reconnaissance faciale se développent surtout à partir des années 90.
L’augmentation de la puissance de calcul des ordinateurs permet notamment l’utilisation de méthodes statistiques et d’apprentissage plus complexes et sur de plus gros volumes de données, permettant un net gain de performance.
C'est ainsi qu'apparaît une méthode de reconnaissance de visages basées sur les eigenfaces.
Aussi préciserons-nous que "eigenface" est le nom donné à un ensemble de vecteurs propres utilisés dans le contexte de reconnaissance faciale.
Cette approche a l'avantage de traiter le problème de reconnaissance faciale uniquement grâce à des images en deux dimensions, sans avoir recours à une géométrie à trois dimensions.
La méthode eigenface commence avec le concept d'espace des images: une image en deux dimensions peut être vue comme un point, ou un vecteur, dans un espace de grande dimension, appelé espace des images.
Par exemple, une image comprenant 32 lignes et 32 colonnes décrit un point dans un espace d'image à 1024 dimensions.
De manière générale, une image comprenant $l$ lignes et $c$ colonnes décrit un point dans un espace à $N = rc$ dimensions.
L'idée de cette méthode est de déterminer un ensemble vecteurs propres d'une matrice de covariance, calculée à partir d'un ensemble d'images de visage (ensemble d'entraînement ou training set), de sorte que n'importe quel visage de l'ensemble de départ puisse être reconstitué à partir d'une combinaison linéaire des vecteurs propres (appelés eigenfaces) précedemment calculés.
Ces eigenfaces nous permettent, de fait, de définir un espace des images.
Une fois les eigenfaces calculés, il nous est possible d'effectuer une détection de visage, ainsi qu'une reconnaissance faciale.
En particulier, il suffit de projeter un vecteur image sur l'espace des visages (défini à partir des eigenfaces) et de calculer la distance euclidienne qui le sépare de sa projection.
Si cette distance dépasse un certain seuil, on considère que l'image ne figure pas un visage. A l'inverse, si cette distance est inférieure à ce seuil, l'image est bien celle d'un visage.

\section{Calcul des Eigenfaces}

\subsection{Travail dans $\mathbb{R}^{N \times N}$}
Considérons une image de visage comme une matrice $N \times N$ dont le coefficient $(i,j)$ est égal au niveau de gris du pixel $(i,j)$ (l'origine se situant dans le coin haut gauche).
On transforme ensuite cette matrice comme un vecteur de $\mathbb{R}^{N \times N}$ en juxtaposant les colonnes l'une en dessous de l'autre, par exemple.
\[
  \begin{pmatrix}
    p_{1,1} & p_{1,2} & \cdots & p_{1,N} \\
    p_{2,1} & p_{2,2} & \cdots & p_{2,N} \\
    \vdots  & \vdots  & \ddots & \vdots  \\
    p_{N,1} & p_{N,2} & \cdots & p_{N,N}
  \end{pmatrix}
  \rightarrow
  \begin{pmatrix}
    p_{1,1} \\
    p_{2,1} \\
    \vdots \\
    p_{N,1} \\
    \vdots \\
    p_{1,N} \\
    \vdots \\
    p_{N,N}
  \end{pmatrix}
\]

\subsection{Calcul des valeurs propres et des vecteurs propres de la matrice de covariance}
Les images des visages sont globalement similaires, donc ces images ne seront pas distribuées aléatoirement dans notre espace $\mathbb{R}^{N \times N}$.
On peut donc décrire notre espace des visages de manière plus fine (\textit{i.e.} avec moins de dimensions).


\subsubsection{Matrice de covariance}
Avant de commencer la réduction de l'espace de travail, nous allons d'abord analyser cette dispersion en calculant la matrice de covariance de manière empirique.

\begin{defi}[Matrice de Covariance]
  La matrice de covariance d'un vecteur de $p$ variables aléatoires $\overrightarrow{X} =
  \begin{pmatrix}
    X_1 \\
    \vdots \\
    X_p
  \end{pmatrix}$ dont chacune possède une variance, est la matrice carrée dont le terme générique est donné par $a_{i,j} = \Cov(X_i,X_j)$.
\end{defi}

\begin{defi}[Matrice de Covariance]
  La matrice de covariance, notée parfois $\Sigma$, est définie par :
  \[
    \Var(\overrightarrow{X}) = \esp[(\overrightarrow{X}-\esp(\overrightarrow{X})) (\overrightarrow{X}-\esp(\overrightarrow{X}))^T]
  \]
\end{defi}

\begin{defi}[Estimation de la Matrice de Covariance]
  En partant d’un échantillon de réalisations indépendantes d’un vecteur aléatoire, une estimation de la matrice de covariance est donné par :
  \[
    \Var(\overrightarrow{X}) = \frac{1}{n} \displaystyle\sum_{i=1}^{n} (\overrightarrow{X_i} - \overrightarrow{\mu})(\overrightarrow{X_i}-\overrightarrow{\mu})^T
  \]
  où $\overrightarrow{\mu} = \frac{1}{n} \displaystyle\sum_{i=1}^{n}\overrightarrow{X_i}$ est le vecteur des moyennes empiriques.
\end{defi}

\paragraph{Application à notre cas}
Supposons que nous avons $M$ images de visage. On note $I = [I_1, I_2, \dotsc, I_M]$ la matrice de taille $N^2 \times M$ de l'ensemble de nos images.
\begin{enumerate}
\item On calcule le visage moyen $\Psi = \frac{1}{M}\displaystyle\sum_{i=1}^{M} I_i$.
\item On retire le visage moyen à chacun de nos visages, en effet nous nous intéressons uniquement aux particularités.\\
  Donc, chaque visage différe de la moyenne par le vecteur $\Phi_i = I_i - \Psi$.
\item On calcule la matrice de covariance
  \begin{align*}
    C &= \frac{1}{M} \displaystyle\sum_{i=1}^{M} \Phi_i \Phi_i^T \\
      &= \frac{1}{M} AA^T
  \end{align*}
  où $A = [\Phi_1,\Phi_2,\dotsc,\Phi_M]$ est la matrice $N^2 \times M$ de nos visages centrés.
\end{enumerate}
Cette matrice encode la dispersion de nos images de visages dans $\mathbb{R}^{N^2}$. Les coefficients de la diagonale sont les variances selon les axes $e_1, e_2, \dots, e_{N^2}$.
Les autres coefficients sont la covariance entre deux axes.

\begin{rmq}
  $C$ est symétrique réelle donc diagonalisable dans une base orthonormée. $C$ est également définie semi-postivie, c'est à dire que toutes ses valeurs propres sont positives
\end{rmq}

\subsubsection{Méthode 1: Analyse en composantes principales}
L'analyse en composantes principales consiste à transformer des variables liées entre elles (dites ``corrélées'' en statistique) en nouvelles variables décorrélées les unes des autres.\\
Ces nouvelles variables sont nommées ``composantes principales'', ou axes principaux, dans notre cas elles sont appelées \emph{eigenfaces}.\\
L'ACP nous permet de réduire le nombre de variables et de rendre l'information moins redondante. En effet, nous cherchons les meilleurs axes ou \emph{eigenfaces} décrivant le mieux notre espace de visages.\\

Finalement, nous cherchons le vecteur $u \in \mathbb{R}^{N^2}$ tel que la projection des images des visages sur $u$ ait une variance maximale. Cette projection s'écrit :
\[
  p_u(A)=A^T \cdot u
\]
La variance empirique de $p_u(A)$ vaut donc :
\begin{align*}
  p_u(A)^T \cdot \frac{1}{M} \cdot p_u(A) &= (A^T \cdot u)^T \cdot \frac{1}{M} \cdot (A^T \cdot u)\\
                                          &= u^T \cdot \left( A \cdot \frac{1}{M} \cdot A^T \right) \cdot u\\
                                          &= u^T \cdot C \cdot u
\end{align*}
$C$ est symétrique réelle donc $C$ est diagonalisable dans une base orthonormée,
notons $P$ le changement de base associé et $D = Diag(\lambda_1, \dotsc, \lambda_L)$ la matrice diagonale formée de son spectre rangé en ordre décroissant, on a :
\begin{align*}
  p_u(A)^T \cdot \frac{1}{M} \cdot p_u(A) &= u^T \cdot C \cdot u\\
                                          &= u^T P^T D P u = (Pu)^T D \underbrace{(Pu)}_v
\end{align*}

Le vecteur unitaire $u$ qui maximise $v^T D v$  est un vecteur propre de $C$ associé à la valeur propre $\lambda_1$, on a alors :
\[
  v^T D v = \lambda_1
\]
La valeur propre $\lambda_1$ est la variance empirique sur le premier axe de l'ACP.
On continue la recherche du deuxième axe de projection $w$ sur le même principe en imposant qu'il soit orthogonal à $u$.\\

La diagonalisation de la matrice de covariance, nous a permis d'écrire que le vecteur qui explique le plus d'inertie du nuage est le premier vecteur propre.
De même le deuxième vecteur qui explique la plus grande part de l'inertie restante est le deuxième vecteur propre, etc.\\
Nous avons vu en outre que la variance expliquée par le k-ième vecteur propre vaut $\lambda_k$.\\
Finalement, la question de l'ACP se ramène à un problème de diagonalisation de la matrice de covariance.

\subsubsection{Méthode 2: Décomposition en valeurs singulières}

La décomposition en valeurs singulières permet de factoriser des matrices carrés ou rectangulaires réels ou complexes, on s'intéressera ici au cas réels. \\
Énoncé: Soit $M$ une matrice $m \times n$, alors il existe une décomposition de la forme: \\
$$M=U\Sigma V^t$$
Avec $U$ une matrice unitaire $m \times m$, $\Sigma$ une matrice $m\times n$ où les coefficients diagonaux sont des réels positifs ou nuls et tous les autres sont nuls, et $V$ est une matrice unitaire $n \times n$. On appelle ainsi cette factorisation la décomposition en valeurs singulières de $M$.
\begin{itemize}
\item La matrice $V$ contient un ensemble de vecteurs de base orthonormés de $\mathbb{R}^n$ d'entrée
\item La matrice $U$ contient un ensemble de vecteurs de base orthonormés de $\mathbb{R}^m$ de sortie
\item La matrice $\Sigma$ contient dans ses coefficients diagonaux les valeurs singulières de la matrice $M$. Elles correspondent aux racines des valeurs propres de $M^t M$
\end{itemize}

On appelle ainsi valeur singulière de $M$ toute racine carrée d'une valeur propre de $M^t M$, autrement dit tout réel positif $\lambda$ tel qu'il existe un vecteur unitaire $u$ dans $\mathbb{R}^m$ et un vecteur unitaire $v$ vérifiant dans $\mathbb{R}^n$:
$$ M^t u = \lambda v \text{ et } Mv = \lambda u$$

Dans le cas d'une matrice carrée symétrique définie semi-positive (ce qui est le cas ici pour $C$) les valeurs singulières et vecteurs singuliers correspondent aux valeurs propres et vecteurs propres de M.
De plus les colonnes de $V$ sont les vecteurs propres de $M^tM$ et les colonnes de $U$ sont les vecteurs propre de $MM^t$. Cela va nous aider dans notre cas car si on prend $M$ notre matrice ayant comme colonnes les images vectorisé, alors $MM^t$ correspond à la matrice de covariance recherché (en multipliant par une constante ce qui ne change rien au vecteur propre). Ainsi on peut avoir les vecteur propres de la matrice de covariance sans la calculé (ce qui est très important car ce calcul peut être très long avec une matrice qui devient énorme). 


Il existe plusieurs façon de calculer une décomposition en valeurs singulière. Un algorithme courant consiste en:
\begin{itemize}
\item Effectuer une décomposition QR si la matrice possède plus de lignes que de colonnees
\item Réduire le facteur R sous forme bidiagonale, (on pourra notaement utiliser des transformations de Householder alternativement sur les colonnes et sur les lignes de la matrice).
\item Les valeurs singulières et vecteurs singuliers sont alors trouvés en effectuant une itération de type QR bidiagonale avec la procédure DBDSQR
\end{itemize}

\section{Utilisation des eigenfaces pour classer une image de visage}

\subsection{Projection dans l'espace des visages}
Soit $\Gamma$ une nouvelle image de visage, on la projette dans l'espace des visages par:
$$\omega_k = u_k^T(\Gamma - \Psi)$$
pour $k = 1,~\dots,~M'$, on obtient ainsi un vecteur $W$ tel que:
\[W =
  \begin{pmatrix}
    \omega_1 \\
    \vdots \\
    \omega_{M'}
  \end{pmatrix}
\]
$W$ décrit la contribution de chacun des eigenfaces pour l'image en question.

\subsection{Analyse de la projection}
On peut maintenant utilisé cette projection pour savoir si l'image est un visage et si c'est le cas si c'est un visage connue.
On fait une reconstruction de l'image en question multipliant la projection par une matrice contenant toutes les eigenfaces. On obtient ainsi un vecteur auquel on ajoute le vecteur moyen (puisqu'on l'avait soustrait auparavant), on appelle ce vecteur $\Omega$.
Cette reconstruction doit être très proche de l'image d'origine si celle ci était un visage, c'est pour cela que pour déterminer si l'image est visage on regarde si la distance euclidienne entre l'image d'origine et sa reconstruction est \emph{petite}.\\
Si la distance est en effet petite, on peut alors se demander si c'est un visage connue. Pour ce faire nous devons tout d'abord calculé des classes de visages.\\
Supposons qu'il y ait $i$ individus dans la base de données. Pour calculer la classe correspondant au k-ième individu, on va projeter toutes les images de cet individu puis, faire la moyenne de ces projections (de même on ajoute le vecteur moyen à chaque fois pour faire une reconstruction), on appelle $\Omega_i$ ce vecteur. On obtient ainsi $i$ classe de visage. On cherche alors la classe de visage qui minimise la distance euclidienne entre $\Omega$ et $\Omega_k$. Si cette distance est assez \emph{petite} on peut alors dire que c'est un visage connue. \\
Pour définir ce que veut dire \emph{petit} dans ces deux cas, il faut définir deux seuils $\epsilon_1$ et $\epsilon_2$. Ces deux seuils dépendent du nombre d'image total et du nombre d'image par personne. $\epsilon_1$ est le seuil définissant \emph{proche de l'espace des vsiages} et $\epsilon_2$ est celui définissant \emph{proche d'une classe de visage}.\\

Il y a finalement 4 possibilités pour une image:
\begin{enumerate}
  \item L'image est proche de l'espace des visages et proche d'une classe de visage en particulier, c'est alors un visage connu.
  \item L'image est proche de l'espace des visages mais n'est proche d'aucune classe de visage, c'est alors un visage inconnu
  \item L'image est distante de l'espace des visages mais proche d'une classe de visage, c'est la plupart du temps un faux positif et n'est donc pas un visage.
  \item L'image est distante de l'espace des images et également distante de toutes les classes de visages, on peut alors en conlcure que ce n'est pas un visage.
\end{enumerate}

\subsection{Observation}
La méthode des eigenfaces est très précise pour savoir si une image est un visage, en effet sur 39 tests effectués l'algorithme a toujours renvoyé la bonne réponse (38 étaient des visages et 1 était une plante), la distance dans les deux cas n'avait rien à voir (beaucoup plus élevé pour la plante). De plus dans les cas où la nouvelle image est une photo de quelqu'un faisant partie du training set on remarque que la personne la plus proche en distance euclidienne est toujours la bonne. Cependant sur 37 tests, seulement 29 était considéré comme des visages connues. En effet bien que la bonne classe de visage était trouvé la distance avec cette classe était trop élevé pour qu'on puisse conclure que c'était belle et bien cette personne et le seuil ne pouvait pas être baissé non plus car sinon un individu ne devant pas être reconnue. En clair si nous savions déjà que seuls des personnes du training set allée être testé l'algorithme aurait eu un test parfait car il n'y a même pas besoin de seuil. Mais dans notre cas les distances étaient parfois trop élevé.


\section{Intelligence artificielle, machine learning: les solutions actuelles pour une reconnaissance faciale plus efficace}
La reconnaissance faciale par les Eigenfaces n'est pas forcément la technique la plus utilisée. D'autres techniques sont utilisés dans le domaine de la reconnaissance faciale et visuelle. Notamment on va voir qu'il y a le \textit{ Embedded Hidden Markov Model}(Embedded HMM) et les réseaux neuronaux convolutifs.
\subsection{Embedded HMM}
En français, nous parlons de modèle de Markov caché, ou encore de automate de Markov à états cachés. Nous sommes dans le cadre des probabilités conditionnelles ici. Cette technique est plus utilisé pour de la reconnaissance visuelle, reconnaître des formes, des objets.
Posons la notion de processus de Markov : une fonction aléatoire vérifiant que la distribution conditionnelle de probabilité de l'états futur de l'automate, ne dépend que de l'état présent, et non pas des états passés(propriété de Markov). Soit pour $E^{n+2}$ un ensemble de n+2 états:
\[
  \forall n\geq0, \forall(i_0,..., i_{n-1}, i, j)\in E^{n+2},
\]
\[
  P(X_{n+1}=j | X_0=i_0, X_1=i_1, ..., X_n=i) = P(X_{n+1}=j | X_n=i)
\]
Une chaîne de Markov est un processus de Markov si X est une variable discrète muni par P, la fonction de probabilité.
Au contraire, dans un modèle de Markov caché, nous sommes dans un modèle markovien dont les états d'une exécution sont inconnus(cachés).
Ce modèle est donc utile pour modéliser un système physique probabiliste, utilisé ici dans le cadre d'un algorithme d'optimisation (espérance-maximisation).
Dans le cadre de la reconnaissance d'objets, c'est par l'étude des formes que ce modèle probabiliste propose un objet correspondant à une image reçue.
\subsection{Réseau de neurones convolutifs}
Nous sommes dans le cadre d'un réseau de neurones convolutifs. Le réseau de neurones convolutifs est une branche de l'intelligence artificielle, le Deep Learning.(rappelons que l'analyse d'image est un domaine où le deep learning est utilisé) Le fonctionnement d'un réseau de neurones est similaire aux réseaux de neurones chez l'Homme. Chaque neurone a plusieurs entrées et une seule sortie, et des actions entre les deux. Les réseaux de neurones utilisent de l'algèbre linéaire (multiplication de matrices, dérivées partielles). Un réseau de neurones convolutifs est un réseau de neurones où les motifs de connexions entre les neurones est inspiré par le cortex visuel des humains. Chaque propriété d'une image analysée va occuper une place dans sa reconnaissance. L'analyse d'image ici passe par plusieurs "couches de neurones". Par exemple en premier la luminosité des pixels va être analysée, puis les corrélations entre des pixels voisins, à partir de ces corrélations identifier des lignes directrices, puis regrouper ces lignes directrices pour former des structures, puis identification des structures(par exemple des yeux), puis mettre en lien les identifications pour trouver l'identification de l'image.
Une matrice de convolution est utilisée dans le traitement d'images pour le floutage, l'amélioration de la netteté de l'image, le gaufrage, la détection de contours, etc...
Chaque neurone du réseau analysera une matrice de convolution en fonction du pixel.
Ainsi sont identifié les éléments d'une image, ou un visage sur une image amenant à la reconnaissance faciale.
Ces réseaux de convolutions sont aussi utiles dans la compréhension de texte, en médecine, et même pour le jeu de go(soit lorsqu'il il y a une partielle corrélation globale, relative invariance spatiale ou temporelle(vidéo)).


\newpage

\part{Les différentes utilisations des technologies de reconnaissance faciale}

Le procédé de reconnaissance faciale s'organise en deux temps: la collecte du visage et un "gabarit", c'est-à-dire un modèle représentant,
d'un point de vue informatique, les caractéristiques de ce visage, puis la reconnaissance de visage par comparaison du gabarit correspondant avec un ou plusieurs autres gabarits.

\section{Les besoins auxquels répondent les technologies de reconnaissance faciale}
Comme tout procédé biométrique, la reconnaissance faciale remplit deux fonctions.

\subsection{Authentification}
Premièrement, cette technologie permet l’authentification d’une personne, qui vise à vérifier qu’une personne est bien celle qu’elle prétend être. Dans ce cas, le système va comparer un gabarit biométrique préenregistré avec un seul visage, par exemple celui d’une personne qui se présente à un point de contrôle, afin de vérifier si cette personne est la même.
Cette fonctionnalité repose donc sur la comparaison de deux gabarits.

\subsection{Identification}
Deuxièmement, elle permet l’identification d’une personne, qui vise à retrouver une personne au sein d’un groupe d’individus, dans un lieu, une image ou une base de données.
Dans ce cas, le système doit effectuer un test sur chaque visage capté pour générer un gabarit biométrique et vérifier si celui-ci correspond à une personne connue du système.
Cette fonctionnalité repose ainsi sur la comparaison d’un gabarit avec une base de données de gabarits.
Par exemple, elle permet de lier un « état civil » (nom, prénom) à un visage, si la comparaison est faite avec une base de photographies associées à un nom et un prénom.
Elle peut aussi consister à suivre la trajectoire d’une personne dans une foule, sans nécessairement faire le lien avec l’état civil de la personne.

\section{Les secteurs dans lesquels la reconnaissance faciale est utilisée}
La reconnaissance faciale peut poursuivre des finalités très diverses, aussi bien commerciales que liées à la sécurité publique.
Elle peut s’inscrire dans des lieux très différents : dans la relation personnelle entre un utilisateur et un service, pour l’accès à un endroit spécifique, ou sans limitation particulière dans l’espace public (reconnaissance faciale « à la volée »).

\bigskip

Certains usages de la reconnaissance faciale sont placés sous le contrôle total des utilisateurs.
C'est le cas de l'authentification pour accéder, à différents services ou applications, qui se fait dans un cadre purement domestique.
Nous pourrions notamment citer l'exemple des smartphones, largement répandus: le propriétaire d'un téléphone peut dévérouiller celui-ci en le tenant naturellement, la caméra faciale étant orientée vers son visage.
Enfin, de manière générale, l'authentification par reconnaissance faciale est massivement utilisée, en substitution de l’authentification par mot de passe, par les détenteurs d’ordiphones pour déverrouiller leur appareil.

L’authentification peut aussi être utilisée aux fins de contrôle d’accès physique à un ou plusieurs lieux prédéterminés, par exemple à l’entrée de bâtiments ou à des points de passage particuliers.
Cette fonctionnalité est ainsi mise en œuvre dans le cadre du traitement PARAFE de passage aux frontières,
où la photographie de la personne se présentant au dispositif de contrôle est comparée avec celle contenue dans son titre d’identité (passeport ou titre de séjour sécurisé).


\bigskip

L’identification peut donner lieu à des applications nombreuses et plus diverses.
On peut notamment citer les cas d’usages suivants, constatés ou envisagés en France ou ailleurs en Europe :
\begin{itemize}
\item la reconnaissance automatique de personnes présentes sur une image aux fins d’identifier par exemple ses relations sur un réseau social,
  à l’instar de Facebook qui l’utilise, par comparaison entre l’image et les gabarits de toutes les personnes présentes sur le réseau ayant consenti à cette fonctionnalité, pour suggérer l’identification nominative de ces relations;
\item l’accès à des services, certains distributeurs de billets reconnaissant leurs clients, par comparaison entre un visage capté par une caméra et la base de données de visages détenue par la banque;
\item le suivi du parcours d’un passager d’un service de transport à toutes les étapes de ce parcours,
  par comparaison entre le gabarit calculé en temps réel de toute personne se présentant à des portiques présents à certaines étapes du parcours (déposes bagages, portiques d’embarquement, etc. )
  et les gabarits des personnes enrôlées au préalable au sein du dispositif;
\item la recherche, dans une base de données comportant des photographies, de l’état civil d’une personne (victime, suspecte, etc. ) non identifiée, ainsi que le permet par exemple en France le traitement TAJ (Traitement des antécédents judiciaires);
\item le suivi des déplacements d’une personne dans l’espace public, par comparaison entre son visage et les gabarits biométriques des personnes circulant ou ayant circulé dans la zone surveillée,
  par exemple en cas d’oubli d’un bagage ou à la suite de la commission d’un délit;
\item la reconstitution du parcours d’une personne et de ses interactions successives avec des personnes tierces, par une comparaison des mêmes éléments mais réalisée en différé, pour identifier ses contacts par exemple;
\item l’identification sur la voie publique de personnes recherchées, par confrontation en temps réel de tous les visages captés à la volée par des caméras  de vidéoprotection et une base de données détenue par les forces de l’ordre.
\end{itemize}


\part{Les enjeux de la reconnaissance faciale}

\section{Les risques de cette technologie}

À la différence de toute autre donnée à caractère personnel, la donnée biométrique n’est pas attribuée par un tiers ni même choisie par la personne : elle est produite par le corps lui-même et le désigne ou le représente, lui et nul autre, de façon immuable.
Contrairement à un mot de passe ou un identifiant, elle ne peut dès lors être modifiée en cas de compromission (perte, intrusion dans le système, etc.) : elle est non révocable.
Tout détournement ou mauvais usage de cette donnée fait ainsi peser des risques substantiels sur la personne dont elle émane : privation de ses accès à des services ou à des lieux, usurpation de son identité à des fins d’escroquerie, voire criminelles, etc.

La reconnaissance faciale, tout comme les autres techniques biométriques, n’est donc jamais un traitement tout à fait anodin.
Même un usage légitime et bien cadré peut, en cas de cyberattaque, de compromission ou d’erreur, entraîner des conséquences particulièrement graves.
Dans ce contexte, la question de la sécurisation des données biométriques est essentielle et doit être une priorité impérieuse dans la conception de tout projet de cette nature.
Le stockage des données biométriques sur un support individuel détenu par l’utilisateur, à la main de ce dernier, doit toujours être privilégié aux solutions de stockage en base centrale, afin de minimiser les risques encourus.
Ce n’est qu’en cas d’absolue nécessité, en l’absence de toute alternative, qu’un stockage centralisé peut être
envisagé, sous réserve de strictes mesures de sécurité.

\section{La nécessité de définir les restrictions de l'utilisation de cette technologie}

A ECRIRE

\section*{Conclusion}
Les eigenfaces constituent une méthode de reconnaissance faciale simple et peu chère en ressource en ce sens que son processus d'entraînement est automatique et facile à développer,
elle réduit la complexité de la représentation d'une image de visage (Eigenface n'exige pas d'informations en trois dimensions), et enfin, cette méthode est capable de gérer d'importantes bases de données.

En revanche, Eigenface est très sensible aux changements de luminosité, de taille des images et des visages, et est incapable de reconnaître des expressions faciales.
De fait, aujourd'hui, les technologies intégrant un sytème de reconnaissance faciale n'ont pas recourt à la méthode des eigenfaces.

\newpage
\newpage
\begin{thebibliography}{18}
\bibitem{}
  MIT Press Journal~: Eigenfaces for recognition
  \\\textit{https://www.mitpressjournals.org/doi/abs/10.1162/jocn.1991.3.1.71}
  \\
  \underline{Présentation générale :}

\bibitem{}
  Wikipedia~: Eigenface
  \\\textit{https://en.wikipedia.org/wiki/Eigenface}

\bibitem{}
  Scholarpedia~: Eigenface
  \\\textit{http://www.scholarpedia.org/article/Eigenface}

\bibitem{}
  jmcSpot~: EigenFace
  \\\textit{http://jmcspot.com/Eigenface/}

  \underline{Algorithme :}

\bibitem{}
  Github~: Reconnaissance faciale
  \\\textit{https://github.com/msilanus/faceReco}

\bibitem{}
  Cours IUT BM~: Eigenfaces
  \\\textit{http://cours-info.iut-bm.univ-fcomte.fr/wiki/pmwiki.php/TP/EigenFaces}

\bibitem{}
  Ecole Supérieur d'ingénieur de Rennes : TP Eigenface
  \\\textit{TP-ESIR-Eigenface.pdf}
  \\
  \underline{Mathématiques :}

\bibitem{}
  Wikipedia~: Covariance
  \\\textit{https://fr.wikipedia.org/wiki/Covariance}

\bibitem{}
  Wikipedia~: Analyse en composantes principales
  \\\textit{https://fr.wikipedia.org/wiki/Analyse\_en\_composantes\_principales}

\bibitem{}
  Wikipedia~: Décomposition en valeurs singulières
  \\\textit{https://fr.wikipedia.org/wiki/Decomposition\_en\_valeurs\_singulieres}
  \\
  \underline{Autres :}

\bibitem{}
  ResearchGate~: Article sur les reconnaissances de visages
  \\\textit{https://www.researchgate.net/publication/303907498\_RECONNAISSANCE\_DE\_VISAGES\_HOMMESFEMMES\_PAR\_LES\_EigenFaces\_et\_les\_SVMs}

\bibitem{}
  Alicem
  \\\textit{https://www.interieur.gouv.fr/Actualites/L-actu-du-Ministere/Alicem-la-premiere-solution-d-identite-numerique-regalienne-securisee}

\bibitem{}
  Youtube~: Science4All Réseaux de neurones
  \\\textit{https://www.youtube.com/watch?v=8qL2lSQd9L8}

\bibitem{}
  ENPC~: Chaines de markov
  \\\textit{https://cermics.enpc.fr/~delmas/Enseig/mod-stoch.pdf}

\bibitem{}
  Anefian~: Embedded HMM
  \\\textit{http://www.anefian.com/research/nefian99\_embedded.pdf}

\bibitem{}
  Wikipedia~: Clearview AI
  \\\textit{https://en.wikipedia.org/wiki/Clearview\_AI}

\bibitem{}
  Apple~: Face ID
  \\\textit{https://support.apple.com/fr-fr/HT208109}

\bibitem{}
  Archives ouvertes~: reconnaissance visuelle d'un robot
  \\\textit{https://tel.archives-ouvertes.fr/tel-00758249/document}

\end{thebibliography}


\end{document}
